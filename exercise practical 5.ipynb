{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    train_input = torch.empty(nb, 2).uniform_(-1, 1).type(torch.FloatTensor)\n",
    "    radius = torch.sqrt(torch.pow(torch.abs(train_input[:,0]), 2) + torch.pow(torch.abs(train_input[:,1]), 2))\n",
    "    train_target = torch.LongTensor(np.where((radius>np.sqrt(2/math.pi)), 0, 1))\n",
    "    return train_input, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target=generate_disc_set(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input.size(0)\n",
    "mb_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, traing_target):\n",
    "    epoch_size = 250\n",
    "    learning_rate = 0.1\n",
    "    data_size = train_input.size(0)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(epoch_size):\n",
    "        for batch in range(0, train_input.size(0), mb_size):\n",
    "            output = model(train_input.narrow(0, batch,mb_size))\n",
    "            CrossEntropyLoss = criterion(output, train_target.narrow(0, batch, mb_size))\n",
    "            model.zero_grad()\n",
    "            CrossEntropyLoss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target):\n",
    "    nb_errors = 0\n",
    "    for batch in range(0, train_input.size(0), mb_size):\n",
    "        out = model(data_input.narrow(0, batch,mb_size))\n",
    "        _, pred = torch.max(out, 1)\n",
    "        for counter in range(mb_size):\n",
    "            if data_target[batch + counter] != pred[counter]:\n",
    "                nb_errors += 1\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shallow_model():\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (base)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
