{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the fourth exercise from EPFL EE-559 â€“ DEEP LEARNING course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hello all!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercise itself is located  <a href=\"https://fleuret.org/ee559/materials/ee559-practical-4.pdf\"> here</a><br>\n",
    "For any questions please mail me at tomer@nahshon.net<br>\n",
    "Some of the code here is taken straight from the <a href=\"https://fleuret.org/ee559/src/dlc_practical_4_solution.py\">solution</a> itself but presented in a better visualized way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    eta = 1e-1\n",
    "    criterion = nn.MSELoss()\n",
    "    for e in range(0, 25):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "\n",
    "        print(e, sum_loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "mini_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9222614988684654\n",
      "1 0.7986443713307381\n",
      "2 0.7361812219023705\n",
      "3 0.6806511580944061\n",
      "4 0.6304269134998322\n",
      "5 0.585875429213047\n",
      "6 0.5485511235892773\n",
      "7 0.5188374146819115\n",
      "8 0.5031090676784515\n",
      "9 0.4850390776991844\n",
      "10 0.44415660202503204\n",
      "11 0.4236020930111408\n",
      "12 0.4210911951959133\n",
      "13 0.41060032323002815\n",
      "14 0.378169447183609\n",
      "15 0.3901103623211384\n",
      "16 0.35503595881164074\n",
      "17 0.33910796977579594\n",
      "18 0.3309978637844324\n",
      "19 0.32291887514293194\n",
      "20 0.3112474028021097\n",
      "21 0.29939712956547737\n",
      "22 0.2898037526756525\n",
      "23 0.2875694092363119\n",
      "24 0.2921291943639517\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, train_input, train_target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9223078638315201\n",
      "1 0.7994844764471054\n",
      "2 0.7354758158326149\n",
      "3 0.677043192088604\n",
      "4 0.6261133626103401\n",
      "5 0.584796380251646\n",
      "6 0.5513072162866592\n",
      "7 0.517948966473341\n",
      "8 0.48677581548690796\n",
      "9 0.47102760896086693\n",
      "10 0.44857367500662804\n",
      "11 0.4095415994524956\n",
      "12 0.43664824590086937\n",
      "13 0.38655906170606613\n",
      "14 0.36051754653453827\n",
      "15 0.35297261364758015\n",
      "16 0.35233717039227486\n",
      "17 0.338614659383893\n",
      "18 0.3191841971129179\n",
      "19 0.3187356647104025\n",
      "20 0.31714397110044956\n",
      "21 0.29652771167457104\n",
      "22 0.29213669151067734\n",
      "23 0.2777680493891239\n",
      "24 0.27749719843268394\n",
      "test error Net 14.10% 141/1000\n",
      "0 0.9162067770957947\n",
      "1 0.7941851243376732\n",
      "2 0.7182531803846359\n",
      "3 0.6506625711917877\n",
      "4 0.5935915820300579\n",
      "5 0.5465456880629063\n",
      "6 0.5118890814483166\n",
      "7 0.497282300144434\n",
      "8 0.49226562678813934\n",
      "9 0.43021615594625473\n",
      "10 0.4478701129555702\n",
      "11 0.39254794269800186\n",
      "12 0.37645223736763\n",
      "13 0.3685768321156502\n",
      "14 0.3500896729528904\n",
      "15 0.3349238522350788\n",
      "16 0.32701030001044273\n",
      "17 0.31545907631516457\n",
      "18 0.29730983078479767\n",
      "19 0.2890992611646652\n",
      "20 0.3046106956899166\n",
      "21 0.2842089682817459\n",
      "22 0.2750920467078686\n",
      "23 0.2637155745178461\n",
      "24 0.25504704378545284\n",
      "test error Net 12.90% 129/1000\n",
      "0 0.9025499522686005\n",
      "1 0.7989913001656532\n",
      "2 0.7295419052243233\n",
      "3 0.6691255643963814\n",
      "4 0.6155085489153862\n",
      "5 0.5691361762583256\n",
      "6 0.5300436280667782\n",
      "7 0.4986003078520298\n",
      "8 0.47242481634020805\n",
      "9 0.44876833260059357\n",
      "10 0.425531767308712\n",
      "11 0.4070609621703625\n",
      "12 0.40659790113568306\n",
      "13 0.3794310949742794\n",
      "14 0.3525976240634918\n",
      "15 0.35227666050195694\n",
      "16 0.34629062190651894\n",
      "17 0.3219889421015978\n",
      "18 0.3105216808617115\n",
      "19 0.3084395695477724\n",
      "20 0.30182527005672455\n",
      "21 0.29854576848447323\n",
      "22 0.2993345018476248\n",
      "23 0.2711948752403259\n",
      "24 0.267542764544487\n",
      "test error Net 14.30% 143/1000\n",
      "0 0.878410704433918\n",
      "1 0.7740884870290756\n",
      "2 0.7063602358102798\n",
      "3 0.6450314670801163\n",
      "4 0.5924331694841385\n",
      "5 0.5481671541929245\n",
      "6 0.5125719048082829\n",
      "7 0.48609210178256035\n",
      "8 0.4665292762219906\n",
      "9 0.4405088499188423\n",
      "10 0.43616582080721855\n",
      "11 0.4201525114476681\n",
      "12 0.41120850294828415\n",
      "13 0.3819101005792618\n",
      "14 0.35696965269744396\n",
      "15 0.3521673418581486\n",
      "16 0.33805614337325096\n",
      "17 0.3236079104244709\n",
      "18 0.3272273428738117\n",
      "19 0.31341960467398167\n",
      "20 0.29947815276682377\n",
      "21 0.3137807473540306\n",
      "22 0.2824695333838463\n",
      "23 0.29094318486750126\n",
      "24 0.2805089205503464\n",
      "test error Net 13.00% 130/1000\n",
      "0 0.9414958879351616\n",
      "1 0.7861912772059441\n",
      "2 0.7190099209547043\n",
      "3 0.6600228026509285\n",
      "4 0.6083940155804157\n",
      "5 0.5633190311491489\n",
      "6 0.5286251977086067\n",
      "7 0.5630065761506557\n",
      "8 0.4789860285818577\n",
      "9 0.4514542371034622\n",
      "10 0.44870052114129066\n",
      "11 0.42508069798350334\n",
      "12 0.39411022141575813\n",
      "13 0.38251814618706703\n",
      "14 0.40544403344392776\n",
      "15 0.36379024013876915\n",
      "16 0.34349760226905346\n",
      "17 0.35430627688765526\n",
      "18 0.33519561029970646\n",
      "19 0.31376640126109123\n",
      "20 0.30694569647312164\n",
      "21 0.30633934028446674\n",
      "22 0.3000558614730835\n",
      "23 0.29572708904743195\n",
      "24 0.28092713095247746\n",
      "test error Net 14.50% 145/1000\n",
      "0 0.9290789216756821\n",
      "1 0.8070107623934746\n",
      "2 0.7397433891892433\n",
      "3 0.6742064133286476\n",
      "4 0.6143304482102394\n",
      "5 0.5659167096018791\n",
      "6 0.5286293365061283\n",
      "7 0.5054692775011063\n",
      "8 0.4869171530008316\n",
      "9 0.4497726820409298\n",
      "10 0.4601326771080494\n",
      "11 0.41305600479245186\n",
      "12 0.3901454135775566\n",
      "13 0.38536547124385834\n",
      "14 0.362897802144289\n",
      "15 0.3492320291697979\n",
      "16 0.3629816435277462\n",
      "17 0.3382830135524273\n",
      "18 0.32950255274772644\n",
      "19 0.30179374665021896\n",
      "20 0.3199685849249363\n",
      "21 0.3001109939068556\n",
      "22 0.28226090781390667\n",
      "23 0.28115323185920715\n",
      "24 0.2647537235170603\n",
      "test error Net 12.90% 129/1000\n",
      "0 0.9385503381490707\n",
      "1 0.8375753909349442\n",
      "2 0.7760641798377037\n",
      "3 0.7187307104468346\n",
      "4 0.665770061314106\n",
      "5 0.617599431425333\n",
      "6 0.5749953091144562\n",
      "7 0.5387522466480732\n",
      "8 0.5087858140468597\n",
      "9 0.4847807064652443\n",
      "10 0.46793724969029427\n",
      "11 0.4534291662275791\n",
      "12 0.4320114441215992\n",
      "13 0.4151691608130932\n",
      "14 0.4010275825858116\n",
      "15 0.38251304998993874\n",
      "16 0.3655744306743145\n",
      "17 0.354612423107028\n",
      "18 0.3709208779036999\n",
      "19 0.3558269329369068\n",
      "20 0.31677483953535557\n",
      "21 0.30579437129199505\n",
      "22 0.2976258471608162\n",
      "23 0.3122890293598175\n",
      "24 0.30647152848541737\n",
      "test error Net 17.00% 170/1000\n",
      "0 0.9069949612021446\n",
      "1 0.8255410492420197\n",
      "2 0.7753181234002113\n",
      "3 0.7279815003275871\n",
      "4 0.6813599914312363\n",
      "5 0.6363180093467236\n",
      "6 0.5945910029113293\n",
      "7 0.5582666806876659\n",
      "8 0.5280067697167397\n",
      "9 0.5030113905668259\n",
      "10 0.48222339898347855\n",
      "11 0.46202708408236504\n",
      "12 0.44209520518779755\n",
      "13 0.42297909036278725\n",
      "14 0.4065072648227215\n",
      "15 0.39488980919122696\n",
      "16 0.3919486664235592\n",
      "17 0.3647032715380192\n",
      "18 0.3502334151417017\n",
      "19 0.36562643200159073\n",
      "20 0.32937120273709297\n",
      "21 0.3163670524954796\n",
      "22 0.3103212919086218\n",
      "23 0.3217479884624481\n",
      "24 0.3071338143199682\n",
      "test error Net 15.90% 159/1000\n",
      "0 0.9085213541984558\n",
      "1 0.7813666686415672\n",
      "2 0.7026701048016548\n",
      "3 0.6360621564090252\n",
      "4 0.5841631293296814\n",
      "5 0.5495731569826603\n",
      "6 0.522845271974802\n",
      "7 0.49004000797867775\n",
      "8 0.46397602185606956\n",
      "9 0.44605400413274765\n",
      "10 0.43182777613401413\n",
      "11 0.42380888387560844\n",
      "12 0.40105172246694565\n",
      "13 0.37947436422109604\n",
      "14 0.3575040474534035\n",
      "15 0.33803857304155827\n",
      "16 0.3257727771997452\n",
      "17 0.32089970260858536\n",
      "18 0.3250599801540375\n",
      "19 0.2968592271208763\n",
      "20 0.29079469852149487\n",
      "21 0.3046044483780861\n",
      "22 0.2714722231030464\n",
      "23 0.26212501153349876\n",
      "24 0.27162049897015095\n",
      "test error Net 14.80% 148/1000\n",
      "0 0.9285266622900963\n",
      "1 0.8070313185453415\n",
      "2 0.7383511513471603\n",
      "3 0.6791504323482513\n",
      "4 0.6267293281853199\n",
      "5 0.5823673792183399\n",
      "6 0.5475894026458263\n",
      "7 0.5341108590364456\n",
      "8 0.5062929205596447\n",
      "9 0.4665002375841141\n",
      "10 0.44955945387482643\n",
      "11 0.46770574524998665\n",
      "12 0.41308264806866646\n",
      "13 0.4172920100390911\n",
      "14 0.3844350278377533\n",
      "15 0.37757858261466026\n",
      "16 0.3749326504766941\n",
      "17 0.3407159987837076\n",
      "18 0.3375057205557823\n",
      "19 0.35984595119953156\n",
      "20 0.3165012877434492\n",
      "21 0.3195349480956793\n",
      "22 0.30521359853446484\n",
      "23 0.31605630554258823\n",
      "24 0.2932332567870617\n",
      "test error Net 15.90% 159/1000\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    model = Net()\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3 (base)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
